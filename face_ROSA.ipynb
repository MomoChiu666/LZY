{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from deepgaze.color_detection import RangeColorDetector\n",
    "from deepgaze.mask_analysis import BinaryMaskAnalyser\n",
    "import datetime\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from mediapipe import solutions\n",
    "from mediapipe.framework.formats import landmark_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 提取特定区域的函数\n",
    "def draw_polygon(image, points, color):\n",
    "    points = np.array(points, dtype=np.int32)\n",
    "    cv2.polylines(image, [points], isClosed=True, color=color, thickness=2)\n",
    "\n",
    "        \n",
    "def drawROI(title, video_code, image, points, counter):\n",
    "    output_file = \"./pngFromVideo/\" + video_code + \"/\" + title + \"_\" + str(counter).zfill(5) + \".jpg\"\n",
    "    if not os.path.exists(os.path.dirname(output_file)):\n",
    "        os.makedirs(os.path.dirname(output_file))\n",
    "    # 创建一个与原始图像相同大小的黑色遮罩\n",
    "    mask = np.zeros_like(image)\n",
    "\n",
    "    # 将 forehead_points 转换为 NumPy 数组\n",
    "    points = np.array(points, dtype=np.int32)\n",
    "\n",
    "    # 在遮罩上绘制多边形\n",
    "    cv2.fillPoly(mask, [points], color=(255, 255, 255))\n",
    "\n",
    "    # 将遮罩应用到原始图像上\n",
    "    result_image = cv2.bitwise_and(image, mask)\n",
    "\n",
    "    # 显示结果图像\n",
    "    ##cv2.imshow(\"Forehead Region\", result_image)\n",
    "    cv2.imwrite(output_file, result_image)\n",
    "    ##cv2.destroyAllWindows()\n",
    "    \n",
    "def detectFace(video_code):\n",
    "    # 設定方法\n",
    "    BaseOptions = mp.tasks.BaseOptions\n",
    "    FaceLandmarker = mp.tasks.vision.FaceLandmarker\n",
    "    FaceLandmarkerOptions = mp.tasks.vision.FaceLandmarkerOptions\n",
    "    VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "    ##video_path = \"./Video/\" + video_code +\".mp4\"\n",
    "    video_path = \"D:/2_NCU/1121_碩論/心律檢測影片/\" + video_code +\".mov\"\n",
    "    print(video_path)\n",
    "\n",
    "    # 人臉偵測設定\n",
    "    options = FaceLandmarkerOptions(\n",
    "        base_options=BaseOptions(model_asset_path='model/face_landmarker.task'),\n",
    "        running_mode=VisionRunningMode.IMAGE)\n",
    "\n",
    "    forehead_indices = [66,69,108,151,337,299,296,336,9,107]\n",
    "    nose_bridge_indices = [245,244,189,55,8,285,413,464,465,351,6,122]\n",
    "    nose_indices = [ 6,196,236,219,220,5,440,439,456,419]\n",
    "    nose_tip_indices = [5,220,19,440]\n",
    "    left_cheek_indices = [33,7,163,144,145,153,154,155,133,243,244,233,121,142,203,61]\n",
    "    right_cheek_indices = [263,249,390,373,374,380,381,382,362,463,464,453,350,371,375]\n",
    "    upper_lip_indices = [61, 185, 40, 39, 37, 0, 267, 269, 270, 409, 415]\n",
    "    lower_lip_indices = [146, 91, 181, 84, 17, 314, 405, 321, 375, 291]\n",
    "    chin_indices = [200,208,175,428]\n",
    "   \n",
    "\n",
    "    # 執行人臉偵測\n",
    "    with FaceLandmarker.create_from_options(options) as landmarker:\n",
    "        counter = 0 \n",
    "        counter = counter + 1\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        for frame_index in range(total_frames):\n",
    "            ##if frame_index > 200:\n",
    "            ##    break\n",
    "            ret, frame = cap.read()             # 讀取影片的每一幀\n",
    "            if not ret:\n",
    "                print(\"Cannot receive frame\")   # 如果讀取錯誤，印出訊息\n",
    "                ##break\n",
    "                continue\n",
    "            \n",
    "            h, w = frame.shape[:2]  # 畫面高度和寬度\n",
    "            mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame)\n",
    "            face_landmarker_result = landmarker.detect(mp_image)\n",
    "\n",
    "            if face_landmarker_result is None:\n",
    "                continue\n",
    "\n",
    "            face_landmarks_list = face_landmarker_result.face_landmarks\n",
    "            annotated_image = np.copy(frame)\n",
    "\n",
    "            for idx in range(len(face_landmarks_list)):\n",
    "                face_landmarks = face_landmarks_list[idx]\n",
    "                landmarks = [(int(landmark.x * w), int(landmark.y * h)) for landmark in face_landmarks]\n",
    "\n",
    "                # 1. 繪製額頭\n",
    "                forehead_points = [landmarks[i] for i in forehead_indices]\n",
    "                drawROI(\"forehead\", video_code, annotated_image, forehead_points, frame_index)\n",
    "                draw_polygon(annotated_image, forehead_points, (255, 0, 0))\n",
    "                \n",
    "\n",
    "                # 2. 繪製左臉頰\n",
    "                left_cheek_points = [landmarks[i] for i in left_cheek_indices]\n",
    "                drawROI(\"leftCheek\", video_code, annotated_image, left_cheek_points, frame_index)\n",
    "                draw_polygon(annotated_image, left_cheek_points, (0, 255, 0))\n",
    "                \n",
    "\n",
    "                # 3. 繪製右臉頰\n",
    "                right_cheek_points = [landmarks[i] for i in right_cheek_indices]\n",
    "                drawROI(\"rightCheek\", video_code, annotated_image, right_cheek_points, frame_index)\n",
    "                draw_polygon(annotated_image, right_cheek_points, (0, 0, 255))\n",
    "\n",
    "                # 4. 繪製人中\n",
    "                nose_bridge_points = [landmarks[i] for i in nose_bridge_indices]\n",
    "                drawROI(\"noseBridge\", video_code, annotated_image, nose_bridge_points, frame_index)\n",
    "                draw_polygon(annotated_image, nose_bridge_points, (60, 0, 255))\n",
    "                # 5. 繪製鼻子\n",
    "                nose_points = [landmarks[i] for i in nose_indices]\n",
    "                drawROI(\"nose\", video_code, annotated_image, nose_points, frame_index)\n",
    "                draw_polygon(annotated_image, nose_points, (0, 60, 255))\n",
    "                # 5. 繪製鼻頭\n",
    "                nose_tip_points = [landmarks[i] for i in nose_tip_indices]\n",
    "                drawROI(\"noseTip\", video_code, annotated_image, nose_tip_points, frame_index)\n",
    "                draw_polygon(annotated_image, nose_tip_points, (60, 60, 255))\n",
    "                # 7. 繪製上嘴唇\n",
    "                upper_lip_points = [landmarks[i] for i in upper_lip_indices]\n",
    "                drawROI(\"upperLip\", video_code, annotated_image, upper_lip_points, frame_index)\n",
    "                draw_polygon(annotated_image, upper_lip_points, (255, 255, 0))\n",
    "\n",
    "                # 8. 繪製下嘴唇\n",
    "                lower_lip_points = [landmarks[i] for i in lower_lip_indices]\n",
    "                drawROI(\"lowerLip\", video_code, annotated_image, lower_lip_points, frame_index)\n",
    "                draw_polygon(annotated_image, lower_lip_points, (0, 255, 255))\n",
    "                # 9. 繪製下巴\n",
    "                chin_points = [landmarks[i] for i in chin_indices]\n",
    "                drawROI(\"chinLip\", video_code, annotated_image, chin_points, frame_index)\n",
    "                draw_polygon(annotated_image, chin_points, (0, 255, 255))\n",
    "\n",
    "            ##cv2.imshow('Face Regions', annotated_image)  # 如果讀取成功，顯示該幀的畫面\n",
    "            if cv2.waitKey(10) == ord('q'):  # 每一毫秒更新一次，直到按下 q 結束\n",
    "                break\n",
    "        cap.release()  # 所有作業都完成後，釋放資源\n",
    "        cv2.destroyAllWindows()  # 結束所有視窗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/2_NCU/1121_碩論/心律檢測影片/012_20240605_1133.mov\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def read_ulife_csv(file_in):\n",
    "    ##detectFace(\"012_20240605_1133\")\n",
    "    with open(file_in, mode='r', newline='', encoding=\"utf-8\") as file:\n",
    "        reader = csv.DictReader(file)  # 使用DictReader读取带有表头的CSV文件\n",
    "        for row in reader:\n",
    "            tester_code = \"{}_{}\".format(row[\"編號\"], datetime.datetime.strptime(row[\"量測日期時間\"], \"%Y/%m/%d %H:%M\").strftime(\"%Y%m%d_%H%M\"))\n",
    "            \n",
    "            detectFace(tester_code)\n",
    "            print(tester_code)\n",
    "##read_ulife_csv(\"ulife/uLifePlusApp.csv\")\n",
    "read_ulife_csv(\"ulife/uLifePlusApp_20240531_20240607.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "498b6f2d54bc87ecae66ad14004a9a51e75d6d07f1fa6f949e1304455ff4f085"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
